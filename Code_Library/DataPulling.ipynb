{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa344c7",
   "metadata": {},
   "source": [
    "# MSADS509 Group 3 Final Project: Data Pulling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc06ad",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1f2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea09c89",
   "metadata": {},
   "source": [
    "## Scraping Political Data from CNN and Fox News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da72a1e9-04d3-4644-adbd-1ef36f5d41c7",
   "metadata": {},
   "source": [
    "Below we create a function that scrapes the articles of the day for both Fox News and CNN and creates a pandas data frame using the content that is pulled from the articles. This function pulls the daily articles, and we ran it every day for five consecutive weekdays to get a full business week's worth of data for our topic modeling. This function is here for purposes of showing our methods, but we will ultimately construct the data frame to be cleaned in the cell beneath it by concatenating the five CSV files that were pulled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f5f662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/russia...</td>\n",
       "      <td>CNN — Russia is trying to develop a nuclear sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/15/politics/takeaw...</td>\n",
       "      <td>CNN — The Georgia election subversion case aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/biden-...</td>\n",
       "      <td>Washington CNN — The Norfolk Southern train de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/gaetz-...</td>\n",
       "      <td>CNN — The House Ethics Committee investigating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/takeaw...</td>\n",
       "      <td>CNN — Judge Arthur Engoron hit Donald Trump wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                                url  \\\n",
       "0    cnn  https://www.cnn.com/2024/02/16/politics/russia...   \n",
       "2    cnn  https://www.cnn.com/2024/02/15/politics/takeaw...   \n",
       "3    cnn  https://www.cnn.com/2024/02/16/politics/biden-...   \n",
       "4    cnn  https://www.cnn.com/2024/02/16/politics/gaetz-...   \n",
       "5    cnn  https://www.cnn.com/2024/02/16/politics/takeaw...   \n",
       "\n",
       "                                             content  \n",
       "0  CNN — Russia is trying to develop a nuclear sp...  \n",
       "2  CNN — The Georgia election subversion case aga...  \n",
       "3  Washington CNN — The Norfolk Southern train de...  \n",
       "4  CNN — The House Ethics Committee investigating...  \n",
       "5  CNN — Judge Arthur Engoron hit Donald Trump wi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def return_text_if_not_none(element):\n",
    "    return element.get_text(separator=' ', strip=True) if element else None\n",
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "source = {'cnn': \"https://www.cnn.com/politics\",\n",
    "          'foxnews': \"https://www.foxnews.com/politics\"}\n",
    "\n",
    "news_pages = defaultdict(list)  # Use a list to store URLs and content\n",
    "\n",
    "for source_name, source_page in source.items():\n",
    "    \n",
    "    # request the page and sleep\n",
    "    r = requests.get(source_page)\n",
    "    \n",
    "    time.sleep(5 + 10 * random.random())\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    links = soup.find_all('a', href=True)\n",
    "    \n",
    "    for link in links:\n",
    "        \n",
    "        href = link['href']\n",
    "        # Convert relative URLs to absolute URLs\n",
    "        full_url = urljoin(source_page, href)\n",
    "        \n",
    "        # Check if the link contains \"/politics/\" and does not contain \"/gallery/\"\n",
    "        if \"/politics/\" in full_url and \"/gallery/\" not in full_url:\n",
    "            \n",
    "            # Check if it's CNN and the URL has the format 'cnn.com/{}/'\n",
    "            if source_name == 'cnn' and f\"cnn.com/{current_year}/\" in full_url:\n",
    "                \n",
    "                # Fetch the news content\n",
    "                content_r = requests.get(full_url)\n",
    "                \n",
    "                content_soup = BeautifulSoup(content_r.content, 'html.parser')\n",
    "                \n",
    "                article_content = return_text_if_not_none(content_soup.find('div', {'class': 'article__content'}))\n",
    "                \n",
    "                news_pages[source_name].append({'url': full_url, 'content': article_content})\n",
    "                \n",
    "            # Check if it's FOXNEWS and the URL does not contain \"/category/\"\n",
    "            elif source_name == 'foxnews' and \"/category/\" not in full_url:\n",
    "                \n",
    "                # Fetch the news content\n",
    "                content_r = requests.get(full_url)\n",
    "                \n",
    "                content_soup = BeautifulSoup(content_r.content, 'html.parser')\n",
    "                \n",
    "                article_content = return_text_if_not_none(content_soup.find('div', {'class': 'article-content'}))\n",
    "                \n",
    "                news_pages[source_name].append({'url': full_url, 'content': article_content})\n",
    "# Create a DataFrame\n",
    "\n",
    "df = pd.DataFrame([(source_name, item['url'], item['content']) for source_name, items in \n",
    "                   news_pages.items() for item in items], columns=['source', 'url', 'content'])\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f62f4",
   "metadata": {},
   "source": [
    "## News Counts for CNN and Fox News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5926e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN rows: 48\n",
      "Fox News rows: 20\n"
     ]
    }
   ],
   "source": [
    "source_counts = df['source'].value_counts()\n",
    "\n",
    "# Print the counts for each source\n",
    "print(\"CNN rows:\", source_counts.get('cnn', 0))\n",
    "print(\"Fox News rows:\", source_counts.get('foxnews', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412f06d",
   "metadata": {},
   "source": [
    "## Saving FoxNews and CNN Political News Results from Feb 12 to Feb 16 to Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a2db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0212.csv', index=False)\n",
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0213.csv', index=False)\n",
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0214.csv', index=False)\n",
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0215.csv', index=False)\n",
    "df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0216.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
