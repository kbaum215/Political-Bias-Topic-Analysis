{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa344c7",
   "metadata": {},
   "source": [
    "# MSADS509 Group 3 Final Project: Data Pulling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc06ad",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a1f2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "#from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea09c89",
   "metadata": {},
   "source": [
    "## Scraping Political Data from CNN and Fox News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f5f662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/russia...</td>\n",
       "      <td>CNN — Russia is trying to develop a nuclear sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/15/politics/takeaw...</td>\n",
       "      <td>CNN — The Georgia election subversion case aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/biden-...</td>\n",
       "      <td>Washington CNN — The Norfolk Southern train de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/gaetz-...</td>\n",
       "      <td>CNN — The House Ethics Committee investigating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn</td>\n",
       "      <td>https://www.cnn.com/2024/02/16/politics/takeaw...</td>\n",
       "      <td>CNN — Judge Arthur Engoron hit Donald Trump wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source                                                url  \\\n",
       "0    cnn  https://www.cnn.com/2024/02/16/politics/russia...   \n",
       "2    cnn  https://www.cnn.com/2024/02/15/politics/takeaw...   \n",
       "3    cnn  https://www.cnn.com/2024/02/16/politics/biden-...   \n",
       "4    cnn  https://www.cnn.com/2024/02/16/politics/gaetz-...   \n",
       "5    cnn  https://www.cnn.com/2024/02/16/politics/takeaw...   \n",
       "\n",
       "                                             content  \n",
       "0  CNN — Russia is trying to develop a nuclear sp...  \n",
       "2  CNN — The Georgia election subversion case aga...  \n",
       "3  Washington CNN — The Norfolk Southern train de...  \n",
       "4  CNN — The House Ethics Committee investigating...  \n",
       "5  CNN — Judge Arthur Engoron hit Donald Trump wi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def return_text_if_not_none(element):\n",
    "    return element.get_text(separator=' ', strip=True) if element else None\n",
    "\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "source = {'cnn': \"https://www.cnn.com/politics\",\n",
    "          'foxnews': \"https://www.foxnews.com/politics\"}\n",
    "\n",
    "news_pages = defaultdict(list)  # Use a list to store URLs and content\n",
    "\n",
    "for source_name, source_page in source.items():\n",
    "    \n",
    "    # request the page and sleep\n",
    "    r = requests.get(source_page)\n",
    "    \n",
    "    time.sleep(5 + 10 * random.random())\n",
    "    \n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    links = soup.find_all('a', href=True)\n",
    "    \n",
    "    for link in links:\n",
    "        \n",
    "        href = link['href']\n",
    "        # Convert relative URLs to absolute URLs\n",
    "        full_url = urljoin(source_page, href)\n",
    "        \n",
    "        # Check if the link contains \"/politics/\" and does not contain \"/gallery/\"\n",
    "        if \"/politics/\" in full_url and \"/gallery/\" not in full_url:\n",
    "            \n",
    "            # Check if it's CNN and the URL has the format 'cnn.com/{}/'\n",
    "            if source_name == 'cnn' and f\"cnn.com/{current_year}/\" in full_url:\n",
    "                \n",
    "                # Fetch the news content\n",
    "                content_r = requests.get(full_url)\n",
    "                \n",
    "                content_soup = BeautifulSoup(content_r.content, 'html.parser')\n",
    "                \n",
    "                article_content = return_text_if_not_none(content_soup.find('div', {'class': 'article__content'}))\n",
    "                \n",
    "                news_pages[source_name].append({'url': full_url, 'content': article_content})\n",
    "                \n",
    "            # Check if it's FOXNEWS and the URL does not contain \"/category/\"\n",
    "            elif source_name == 'foxnews' and \"/category/\" not in full_url:\n",
    "                \n",
    "                # Fetch the news content\n",
    "                content_r = requests.get(full_url)\n",
    "                \n",
    "                content_soup = BeautifulSoup(content_r.content, 'html.parser')\n",
    "                \n",
    "                article_content = return_text_if_not_none(content_soup.find('div', {'class': 'article-content'}))\n",
    "                \n",
    "                news_pages[source_name].append({'url': full_url, 'content': article_content})\n",
    "# Create a DataFrame\n",
    "\n",
    "df = pd.DataFrame([(source_name, item['url'], item['content']) for source_name, items in \n",
    "                   news_pages.items() for item in items], columns=['source', 'url', 'content'])\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f62f4",
   "metadata": {},
   "source": [
    "## News Counts for CNN and Fox News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5926e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN rows: 48\n",
      "Fox News rows: 20\n"
     ]
    }
   ],
   "source": [
    "source_counts = df['source'].value_counts()\n",
    "\n",
    "# Print the counts for each source\n",
    "print(\"CNN rows:\", source_counts.get('cnn', 0))\n",
    "print(\"Fox News rows:\", source_counts.get('foxnews', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412f06d",
   "metadata": {},
   "source": [
    "## Saving FoxNews and CNN Political News Results from Feb 12 to Feb 16 to Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a2db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0212.csv', index=False)\n",
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0213.csv', index=False)\n",
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0214.csv', index=False)\n",
    "#df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0215.csv', index=False)\n",
    "df.to_csv('/Users/UE/Desktop/MSADS509_News_Project_Dataset/news_0216.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
